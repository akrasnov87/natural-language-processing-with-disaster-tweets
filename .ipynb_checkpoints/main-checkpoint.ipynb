{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a12ea0a6",
   "metadata": {},
   "source": [
    "# Natural Language Processing with Disaster Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dca546b",
   "metadata": {},
   "source": [
    "## Описание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb56e40",
   "metadata": {},
   "source": [
    "В этом конкурсе требуется создать модель машинного обучения, которая предсказывает, какие твиты посвящены реальным катастрофам, а какие нет."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815d97da",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfdf4ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pathlib==1.0.1 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b679ab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import random \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bf7c1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54e8dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# объявляем переменную для хранения данных\n",
    "DIR='./data'\n",
    "CACHE='./data/cache'\n",
    "RANDOM_STATE=12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99eba4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7613 entries, 1 to 10873\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   keyword   7552 non-null   object\n",
      " 1   location  5080 non-null   object\n",
      " 2   text      7613 non-null   object\n",
      " 3   target    7613 non-null   int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 297.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword location                                               text  target\n",
       "id                                                                            \n",
       "1      NaN      NaN  Our Deeds are the Reason of this #earthquake M...       1\n",
       "4      NaN      NaN             Forest fire near La Ronge Sask. Canada       1\n",
       "5      NaN      NaN  All residents asked to 'shelter in place' are ...       1\n",
       "6      NaN      NaN  13,000 people receive #wildfires evacuation or...       1\n",
       "7      NaN      NaN  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{DIR}/train.csv', index_col='id')\n",
    "\n",
    "df.info()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08e5e2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#проверим на дисбаланс целевого признака\n",
    "df['target'].value_counts().plot(kind='bar')\n",
    "plt.title('Дисбаланс целевого признака')\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47504785",
   "metadata": {},
   "source": [
    "__Примечание__: существенного дисбаланса не видно"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58a0b17",
   "metadata": {},
   "source": [
    "## Заполнение пропусков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115d89da",
   "metadata": {},
   "source": [
    "### Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57abd465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3341"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверяем уникальность\n",
    "df['location'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "204f46a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2533"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['location'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ef56fe",
   "metadata": {},
   "source": [
    "Заполнять попуски будем при помощи дополнительной модели, которая будет предсказывать наличия страны (города) в `location`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c96aba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9af1fd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# заранее отбёрём только те, у которых location заполнен\n",
    "dfl = df.loc[~df['location'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32f373d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data file location\n",
    "DFL_NAME = CACHE + '/dfl.csv'\n",
    "\n",
    "if os.path.exists(DFL_NAME):\n",
    "    dfl = pd.read_csv(DFL_NAME)\n",
    "else:\n",
    "    MODEL_PATH = \"ml6team/bert-base-uncased-city-country-ner\"\n",
    "    model = AutoModelForTokenClassification.from_pretrained(MODEL_PATH)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "    # The model predicts 3 different tags: OTHER, CITY and COUNTRY\n",
    "    nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\", device=device)\n",
    "\n",
    "    def is_country(txt):\n",
    "        pred = nlp(txt)\n",
    "        pbar.update(1)\n",
    "\n",
    "        if len(pred) > 0:\n",
    "            return 1 if pred[0]['entity_group'] != 'OTHER' else 0\n",
    "\n",
    "        return 0\n",
    "\n",
    "    # новый целевой признак, содержится ли в подстроке location упоминание о городе\n",
    "    with tqdm(total=dfl.shape[0]) as pbar:\n",
    "        dfl['isCountry'] = dfl['location'].apply(is_country)\n",
    "\n",
    "    dfl.to_csv(CACHE + '/dfl.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a50bfa6",
   "metadata": {},
   "source": [
    "Обучим модель для определения принадлежности твита к \"стране\" или \"городу\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "626a5815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3835\n",
       "0    1245\n",
       "Name: isCountry, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfl['isCountry'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d32acb4",
   "metadata": {},
   "source": [
    "Заметен дисбаланс \"классов\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b67f0dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from torch.utils.data import TensorDataset\n",
    "from datasets import Dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f39cd28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    0: \"OTHER\",\n",
    "    1: \"COUNTRY\"\n",
    "}\n",
    "label2id = {\n",
    "    \"OTHER\": 0,\n",
    "    \"COUNTRY\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c1ff594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_PATH, \n",
    "        num_labels=2,\n",
    "        label2id=label2id,\n",
    "        id2label=id2label)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb6f433f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Поиск максимальной длины твита\n",
    "seq_len = [len(tokenizer.encode(i, add_special_tokens=True)) for i in dfl['text']]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 100)\n",
    "plt.title('Распределение длины токенов')\n",
    "plt.xlabel('Длина токенов')\n",
    "\n",
    "plt.ylabel('Количество')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c01959ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# округлим до степени 2 (16, 32, 64)\n",
    "max_seq_len = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "684a106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# специально переименовывем колонку целевого признака\n",
    "dfl = dfl.rename(columns={'target': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d84e0568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаём dataset\n",
    "# для тестирования выделяем 10%\n",
    "raw_datasets = Dataset.from_pandas(dfl, preserve_index=False).train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a650aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f467791e2b948ff9296febb508277ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4572 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807e6ebdcf3848aeb1946efccf795db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/508 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"],\n",
    "                     padding=\"max_length\",\n",
    "                     max_length=max_seq_len,\n",
    "                     truncation=True,\n",
    "                     return_attention_mask=True,\n",
    "                     return_token_type_ids=True,\n",
    "                     return_tensors='pt')\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "\n",
    "train_dataset = tokenized_datasets[\"train\"]\n",
    "eval_dataset = tokenized_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bc790d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'keyword', 'location', 'text', 'label', 'isCountry', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 4572\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ea78584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88072122, 1.15664845])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_wts = compute_class_weight(class_weight='balanced',\n",
    "                                 classes=np.unique(dfl['label']),\n",
    "                                 y=dfl['label'])\n",
    "\n",
    "class_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c877d7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights= torch.tensor(class_wts, dtype=torch.float)\n",
    "weights = weights.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf8dacf",
   "metadata": {},
   "source": [
    "Создаём собственный тренажёр для обновления функции потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b19d944",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedLossTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        \"\"\"\n",
    "        Переопределяем для учёта баланса классов\n",
    "        \"\"\"\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "\n",
    "        labels = inputs.get('labels')\n",
    "\n",
    "        loss_func = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "        loss = loss_func(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bb6024",
   "metadata": {},
   "source": [
    "Определяем метрику F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26aadb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a-krasnov\\AppData\\Local\\Temp\\ipykernel_13832\\3470913139.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"f1\")\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return { \"f1\": metric.compute(predictions=predictions, references=labels) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a35d3320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаём бач рекомедованного размера (можно быть либо 32, либо 16)\n",
    "batch_size = 32\n",
    "# количество эпох для обучения\n",
    "train_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be9c6878",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_steps = len(train_dataset) // batch_size\n",
    "\n",
    "training_args = TrainingArguments(\"test_trainer_keyword\",\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  num_train_epochs=train_epochs,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  logging_steps=logging_steps)\n",
    "\n",
    "trainer = WeightedLossTrainer(model=model,\n",
    "                              args=training_args,\n",
    "                              train_dataset=train_dataset,\n",
    "                              eval_dataset=eval_dataset,\n",
    "                              compute_metrics=compute_metrics,\n",
    "                              tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e6f0e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_LOCATION_PATH = CACHE + '/bert-base-uncased-location/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27a813e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# фиксируем state\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "torch.cuda.manual_seed(RANDOM_STATE)\n",
    "\n",
    "if not os.path.exists(MODEL_LOCATION_PATH):\n",
    "    trainer.train()\n",
    "    trainer.save_model(MODEL_LOCATION_PATH)\n",
    "    trainer_eval = trainer.evaluate()\n",
    "    print(f'Результат метрики F1 равно', round(trainer_eval['eval_f1']['f1'], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd57dcda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_LOCATION_PATH)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_LOCATION_PATH, num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f42700a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2533"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfl = df[df['location'].isna()]\n",
    "\n",
    "dfl.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4a9ee8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'COUNTRY', 'score': 0.9993045330047607}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=device)\n",
    "nlp('Forest fire near La Ronge Sask. Canada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84f07580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2533/2533 [02:43<00:00, 12.40it/s]C:\\Users\\a-krasnov\\AppData\\Local\\Temp\\ipykernel_13832\\3613308982.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfl['isCountry'] = dfl['text'].apply(is_country)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2533/2533 [02:45<00:00, 15.35it/s]\n"
     ]
    }
   ],
   "source": [
    "def is_country(txt):\n",
    "    pred = nlp(txt)\n",
    "    pbar.update(1)\n",
    "\n",
    "    if len(pred) > 0:\n",
    "        return 1 if pred[0]['label'] != 'OTHER' else 0\n",
    "\n",
    "    return 0\n",
    "\n",
    "# новый целевой признак, содержится ли в подстроке location упоминание о городе\n",
    "with tqdm(total=dfl.shape[0]) as pbar:\n",
    "    dfl['isCountry'] = dfl['text'].apply(is_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9edfda31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>isCountry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8855</th>\n",
       "      <td>smoke</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I want to smoke ??</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>electrocute</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kids got Disney version of the game Operation ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>collision</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my favorite lady came to our volunteer meeting...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6648</th>\n",
       "      <td>inundation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sprinklers: FAQ About Lawn Inundation Systems ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3696</th>\n",
       "      <td>destroy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@engineermataRAI ate mataas kc rating..but the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          keyword location                                               text  \\\n",
       "id                                                                              \n",
       "8855        smoke      NaN                                 I want to smoke ??   \n",
       "4402  electrocute      NaN  Kids got Disney version of the game Operation ...   \n",
       "2538    collision      NaN  my favorite lady came to our volunteer meeting...   \n",
       "6648   inundation      NaN  Sprinklers: FAQ About Lawn Inundation Systems ...   \n",
       "3696      destroy      NaN  @engineermataRAI ate mataas kc rating..but the...   \n",
       "\n",
       "      target  isCountry  \n",
       "id                       \n",
       "8855       0          0  \n",
       "4402       0          0  \n",
       "2538       1          0  \n",
       "6648       0          0  \n",
       "3696       0          0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfl.loc[dfl['isCountry'] == False].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "905dbeb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4289\n",
       "1    3324\n",
       "Name: isCountry, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(CACHE + '/df_normal_location.csv'):\n",
    "    # создадим новый признак в основной DataFrame\n",
    "    with tqdm(total=df.shape[0]) as pbar:\n",
    "        df['isCountry'] = df['text'].apply(is_country)\n",
    "        \n",
    "    df.to_csv(CACHE + '/df_normal_location.csv')\n",
    "\n",
    "df = pd.read_csv(CACHE + '/df_normal_location.csv')\n",
    "df['isCountry'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a77d89",
   "metadata": {},
   "source": [
    "### Keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707e616a",
   "metadata": {},
   "source": [
    "Аналогично `location` выполним обработку поля `keyword`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "685ff117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['keyword'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2a3526f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['keyword'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ff0ee5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# после просмотра значений, заменим специальный символ на пробел\n",
    "df['keyword'] = df['keyword'].str.replace('%20', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "72b9c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# заранее отбёрём только те, у которых location заполнен\n",
    "dfk = df.loc[~df['keyword'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9afe3b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fatalities             45\n",
       "deluge                 42\n",
       "armageddon             42\n",
       "sinking                41\n",
       "damage                 41\n",
       "                       ..\n",
       "forest fire            19\n",
       "epicentre              12\n",
       "threat                 11\n",
       "inundation             10\n",
       "radiation emergency     9\n",
       "Name: keyword, Length: 221, dtype: int64"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfk['keyword'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "63168775",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = list(dfk['keyword'].unique())\n",
    "\n",
    "for idx in range(len(keywords)):\n",
    "    id2label[idx] = keywords[idx].upper()\n",
    "    label2id[keywords[idx].upper()] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "619453d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=221, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_PATH, \n",
    "        num_labels=len(keywords),\n",
    "        label2id=label2id,\n",
    "        id2label=id2label)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "38f8d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# округлим до степени 2 (16, 32, 64)\n",
    "max_seq_len = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6ba55ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7552 entries, 31 to 7582\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   id         7552 non-null   int64 \n",
      " 1   keyword    7552 non-null   object\n",
      " 2   location   5080 non-null   object\n",
      " 3   text       7552 non-null   object\n",
      " 4   target     7552 non-null   int64 \n",
      " 5   isCountry  7552 non-null   int64 \n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 413.0+ KB\n"
     ]
    }
   ],
   "source": [
    "dfk.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "003d7103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a34bb692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a-krasnov\\AppData\\Local\\Temp\\ipykernel_13832\\4018264777.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfk['keyword'] = data_ordinal\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "data_ordinal = encoder.fit_transform(dfk['keyword'])\n",
    "\n",
    "dfk['keyword'] = data_ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "51af0375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# специально переименовывем колонку целевого признака\n",
    "dfk = dfk.rename(columns={'keyword': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1b547173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b38fe299a46348ebb4272dde75805d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6796 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f22cbee0aef490da648902ad6b9e707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/756 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# создаём dataset\n",
    "# для тестирования выделяем 10%\n",
    "raw_datasets = Dataset.from_pandas(dfk, preserve_index=False).train_test_split(test_size=0.1)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"],\n",
    "                     padding=\"max_length\",\n",
    "                     max_length=max_seq_len,\n",
    "                     truncation=True,\n",
    "                     return_attention_mask=True,\n",
    "                     return_token_type_ids=True,\n",
    "                     return_tensors='pt')\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "\n",
    "train_dataset = tokenized_datasets[\"train\"]\n",
    "eval_dataset = tokenized_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "76a76b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_wts = compute_class_weight(class_weight='balanced',\n",
    "                                 classes=np.unique(dfk['label']),\n",
    "                                 y=dfk['label'])\n",
    "\n",
    "weights= torch.tensor(class_wts, dtype=torch.float)\n",
    "weights = weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b89d4acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return { \"f1\": metric.compute(predictions=predictions, references=labels, average=\"weighted\") }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "fe61df8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаём бач рекомедованного размера (можно быть либо 32, либо 16)\n",
    "batch_size = 32\n",
    "# количество эпох для обучения\n",
    "train_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a49b003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_steps = len(train_dataset) // batch_size\n",
    "\n",
    "training_args = TrainingArguments(\"test_trainer_keyword\",\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  num_train_epochs=train_epochs,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  logging_steps=logging_steps)\n",
    "\n",
    "trainer = WeightedLossTrainer(model=model,\n",
    "                              args=training_args,\n",
    "                              train_dataset=train_dataset,\n",
    "                              eval_dataset=eval_dataset,\n",
    "                              compute_metrics=compute_metrics,\n",
    "                              tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "848386f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_KEYWORD_PATH = CACHE + '/bert-base-uncased-keyword/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "16b8b044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a-krasnov\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2130' max='2130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2130/2130 2:17:08, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.812500</td>\n",
       "      <td>3.458012</td>\n",
       "      <td>{'f1': 0.647503947734303}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.101000</td>\n",
       "      <td>2.855781</td>\n",
       "      <td>{'f1': 0.7532274750528719}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.550100</td>\n",
       "      <td>2.372598</td>\n",
       "      <td>{'f1': 0.8122282567295355}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.082800</td>\n",
       "      <td>2.005795</td>\n",
       "      <td>{'f1': 0.8346487066725162}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.705100</td>\n",
       "      <td>1.737196</td>\n",
       "      <td>{'f1': 0.8432894161904186}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.422300</td>\n",
       "      <td>1.527225</td>\n",
       "      <td>{'f1': 0.8499111160660869}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.217500</td>\n",
       "      <td>1.389491</td>\n",
       "      <td>{'f1': 0.8508518346655356}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.071500</td>\n",
       "      <td>1.301445</td>\n",
       "      <td>{'f1': 0.8544717450314778}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.980200</td>\n",
       "      <td>1.246208</td>\n",
       "      <td>{'f1': 0.8542536136625527}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.931000</td>\n",
       "      <td>1.234886</td>\n",
       "      <td>{'f1': 0.854659600973302}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат метрики F1 равно 0.855\n"
     ]
    }
   ],
   "source": [
    "# фиксируем state\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "torch.cuda.manual_seed(RANDOM_STATE)\n",
    "\n",
    "if not os.path.exists(MODEL_KEYWORD_PATH):\n",
    "    trainer.train()\n",
    "    trainer.save_model(MODEL_KEYWORD_PATH)\n",
    "    trainer_eval = trainer.evaluate()\n",
    "    print(f'Результат метрики F1 равно', round(trainer_eval['eval_f1']['f1'], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "0d49e713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=221, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_KEYWORD_PATH)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_KEYWORD_PATH, num_labels=len(keywords))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "50b27e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'FOREST FIRE', 'score': 0.24594949185848236}]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=device)\n",
    "nlp('Forest fire near La Ronge Sask. Canada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcdf162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf6e6a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "0a2bdcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим вектор признаков\n",
    "df = pd.get_dummies(df, columns=['keyword'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c939347",
   "metadata": {},
   "source": [
    "## Text to vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be1dd61",
   "metadata": {},
   "source": [
    "Преобразуем значение поля `text` в вектор и для этого используем `transformers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "12043989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e6a2f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = AutoModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "8e0e1d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "def text2vector(sentences):\n",
    "    #Tokenize sentences\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=128, return_tensors='pt').to(device)\n",
    "\n",
    "    #Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    #Perform pooling. In this case, mean pooling\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "    pbar.update(1)\n",
    "    ar = sentence_embeddings[0].to('cpu').detach().numpy()\n",
    "    return ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "bf249938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# если в во временной папки нет векторов, то создадим его\n",
    "if os.path.exists(DIR + '/text_vectors.pickle'):\n",
    "    text_vectors = pickle.load(open(DIR + '/text_vectors.pickle', 'rb'))\n",
    "    df['text_vector'] = text_vectors\n",
    "else:\n",
    "    with tqdm(total=df.shape[0]) as pbar:\n",
    "        df['text_vector'] = df['text'].apply(lambda x: text2vector(x))\n",
    "\n",
    "    pickle.dump(df['text_vector'], file = open(DIR + '/text_vectors.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b3b92f",
   "metadata": {},
   "source": [
    "## Location & Keyword to vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3136b1",
   "metadata": {},
   "source": [
    "Объеденим вектор `location` и `keyword`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "08fe1579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание вектора\n",
    "df['feature_vector'] = df.drop(columns=['text_vector', \n",
    "                                        'text', \n",
    "                                        'location', \n",
    "                                        'target', \n",
    "                                        'location_word_count']) \\\n",
    "                        .apply(lambda x: x.values, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced6f714",
   "metadata": {},
   "source": [
    "Объеденим два вектора `feature_vector` и `text_vector`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f735a394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_vectors(row):\n",
    "    \"\"\"\n",
    "    Объединяем два вектора\n",
    "\n",
    "    Параметры:\n",
    "    ----------\n",
    "    row: Serias\n",
    "\n",
    "    Результаты:\n",
    "    numpy.ndarray - объдинённый вектор\n",
    "    \"\"\"\n",
    "\n",
    "    return np.concatenate((row['feature_vector'], row['text_vector']))\n",
    "\n",
    "df['finish_vector'] = df.apply(join_vectors, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "1871456d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина итогового вектора равна 225 + 768 = 993\n"
     ]
    }
   ],
   "source": [
    "print(f'Длина итогового вектора равна {df.iloc[0][\"feature_vector\"].shape[0]} + {df.iloc[0][\"text_vector\"].shape[0]} = {len(df.iloc[0][\"finish_vector\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393b9960",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "2917382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# определим дополнительные переменные\n",
    "RANDOM_STATE=12345\n",
    "N_JOBS = 4\n",
    "CV = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "73e2d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# вектор\n",
    "features = df['finish_vector']\n",
    "# целевой признак\n",
    "target = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "dfe4a4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучающая выборка: 5709\n",
      "Валидационная выборка: 1904\n"
     ]
    }
   ],
   "source": [
    "features_train, features_valid, target_train, target_valid = train_test_split(features, target, test_size=0.25, random_state=RANDOM_STATE, shuffle=True, stratify=target)\n",
    "\n",
    "#features_train, features_test, target_train, target_test = train_test_split(features_train, target_train, test_size=0.25, random_state=RANDOM_STATE, shuffle=True, stratify=target_train)\n",
    "\n",
    "print(f'Обучающая выборка:', features_train.shape[0])\n",
    "#print(f'Тестовая выборка:', features_test.shape[0])\n",
    "print(f'Валидационная выборка:', features_valid.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56ff7ef",
   "metadata": {},
   "source": [
    "Так как все признаки у нас являются числовыми, приведём их к одному распределению (нормализуем)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "6c87d5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "993"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_train.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e093f388",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "features_train = scaler.fit_transform(features_train.tolist())\n",
    "features_valid = scaler.transform(features_valid.tolist())\n",
    "#features_test = scaler.transform(features_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "bf1b5e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(features_train[0], bins=100)\n",
    "\n",
    "plt.title('Распределение')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a15e1e4",
   "metadata": {},
   "source": [
    "Обучим несколько моделей:\n",
    "* LogisticRegression - baseline\n",
    "* RandomForestClassifier\n",
    "* CatBoost\n",
    "* Нейронная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "ee44f503",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "2da6cb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_info(model_name, score):\n",
    "    \"\"\"\n",
    "    Вспомогательная функция для вывода качества метрики\n",
    "    \n",
    "    Параметры:\n",
    "    ----------\n",
    "    model_name: string - имя модели\n",
    "    score: float - показатель метрики\n",
    "    \"\"\"\n",
    "    scores.append([model_name, score])\n",
    "    \n",
    "    print()\n",
    "    print(f'Качество метрики F1 для {model_name} = {round(abs(score), 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b149e39",
   "metadata": {},
   "source": [
    "### LogisticRegression - baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d4369572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': 200, 'penalty': 'l2'}\n",
      "\n",
      "Качество метрики F1 для LogisticRegression = 0.747\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr_model = None\n",
    "lr_gs = None\n",
    "\n",
    "# используем кэш\n",
    "if os.path.exists(DIR + '/lr_gs.pickle'):\n",
    "    lr_gs = pickle.load(open(DIR + '/lr_gs.pickle', 'rb'))\n",
    "    \n",
    "    lr_model = lr_gs.best_estimator_\n",
    "else:\n",
    "    \n",
    "    params = {\n",
    "        'penalty': ['l2'],\n",
    "        'max_iter': [100, 200, 300]\n",
    "    }\n",
    "\n",
    "    lr_gs = GridSearchCV(estimator=LogisticRegression(random_state=RANDOM_STATE, n_jobs=N_JOBS), param_grid=params, cv=CV, scoring='f1', verbose=3)\n",
    "    lr_gs.fit(features_train, target_train)\n",
    "    lr_model = lr_gs.best_estimator_\n",
    "    \n",
    "    pickle.dump(lr_gs, file = open(DIR + '/lr_gs.pickle', 'wb'))\n",
    "\n",
    "print(lr_gs.best_params_)\n",
    "\n",
    "score_info('LogisticRegression', lr_gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f6fda0",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "482cf873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 26, 'n_estimators': 36}\n",
      "\n",
      "Качество метрики F1 для RandomForestClassifier = 0.735\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf_model = None\n",
    "rf_gs = None\n",
    "\n",
    "# используем кэш\n",
    "if os.path.exists(DIR + '/rf_gs.pickle'):\n",
    "    rf_gs = pickle.load(open(DIR + '/rf_gs.pickle', 'rb'))\n",
    "    \n",
    "    rf_model = rf_gs.best_estimator_\n",
    "else:\n",
    "    params = {\n",
    "        \"n_estimators\": range(1, 41, 5),\n",
    "        \"max_depth\": range(1, 41, 5)\n",
    "    }\n",
    "    rf_gs = GridSearchCV(estimator=RandomForestClassifier (random_state=RANDOM_STATE, n_jobs=N_JOBS), param_grid=params, cv=CV, scoring='f1', verbose=3)\n",
    "    rf_gs.fit(features_train, target_train)\n",
    "    rf_model = rf_gs.best_estimator_\n",
    "    \n",
    "    pickle.dump(rf_gs, file = open(DIR + '/rf_gs.pickle', 'wb'))\n",
    "\n",
    "print(rf_gs.best_params_)\n",
    "score_info('RandomForestClassifier', rf_gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a4c265",
   "metadata": {},
   "source": [
    "### CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "eaca0888",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'depth': 8, 'iterations': 1000, 'learning_rate': 0.1}\n",
      "\n",
      "Качество метрики F1 для CatBoostClassifier = 0.77\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cb_model = None\n",
    "cb_gs = None\n",
    "\n",
    "# используем кэш\n",
    "if os.path.exists(DIR + '/cb_gs.pickle'):\n",
    "    cb_gs = pickle.load(open(DIR + '/cb_gs.pickle', 'rb'))\n",
    "    \n",
    "    cb_model = cb_gs.best_estimator_\n",
    "else:\n",
    "    params = {\n",
    "        'iterations': [300, 600, 1000],\n",
    "        'learning_rate': [0.03, 0.1],\n",
    "        'depth': [2, 4, 6, 8]\n",
    "    }\n",
    "\n",
    "    cb_gs = GridSearchCV(estimator=CatBoostClassifier(random_state=RANDOM_STATE, loss_function=\"Logloss\", eval_metric='F1', logging_level='Silent'), param_grid=params, cv=CV, scoring='f1', verbose=3)\n",
    "    cb_gs.fit(features_train, target_train)\n",
    "    cb_model = cb_gs.best_estimator_\n",
    "    \n",
    "    pickle.dump(cb_gs, file = open(DIR + '/cb_gs.pickle', 'wb'))\n",
    "\n",
    "print(cb_gs.best_params_)\n",
    "score_info('CatBoostClassifier', cb_gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358eb415",
   "metadata": {},
   "source": [
    "### Нейронная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "4bb137cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features_train, target_train, test_size=0.25, random_state=RANDOM_STATE, shuffle=True, stratify=target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "010c0bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = torch.FloatTensor(features_train.tolist())\n",
    "features_test = torch.FloatTensor(features_test.tolist())\n",
    "\n",
    "target_train = torch.FloatTensor(target_train.values).reshape(-1, 1)\n",
    "target_test = torch.FloatTensor(target_test.values).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "f2701331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 993])\n",
      "Labels batch shape: torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "# создание датасета\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, target):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.target[idx]\n",
    "\n",
    "# создадим DataLoader\n",
    "train_dataset = CustomDataset(features_train, target_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = CustomDataset(features_test, target_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# проверим работу\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "f6411aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_NEURONS=len(df.iloc[0][\"finish_vector\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "ad8a6af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred, eps=1e-8):\n",
    "    assert y_true.size() == y_pred.size(), \"Input tensors should have the same size\"\n",
    "\n",
    "    # Convert the predicted probabilities to binary predictions\n",
    "    y_pred_binary = torch.round(y_pred)\n",
    "\n",
    "    # Calculate True Positives, False Positives, and False Negatives\n",
    "    tp = torch.sum(y_true * y_pred_binary)\n",
    "    fp = torch.sum((1 - y_true) * y_pred_binary)\n",
    "    fn = torch.sum(y_true * (1 - y_pred_binary))\n",
    "\n",
    "    # Calculate Precision and Recall\n",
    "    precision = tp / (tp + fp + eps)\n",
    "    recall = tp / (tp + fn + eps)\n",
    "\n",
    "    # Calculate F1 Score\n",
    "    f1 = 2 * precision * recall / (precision + recall + eps)\n",
    "\n",
    "    return f1.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "89448364",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(INPUT_NEURONS, INPUT_NEURONS)\n",
    "        self.fc2 = nn.Linear(INPUT_NEURONS, 512)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.fc4 = nn.Linear(512, 512)\n",
    "        self.fc5 = nn.Linear(512, 128)\n",
    "        self.fc6 = nn.Linear(128, 1)\n",
    "\n",
    "        self.dp = nn.Dropout(p=0.2)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.sigm = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dp(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dp(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dp(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dp(x)\n",
    "\n",
    "        x = self.fc5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dp(x)\n",
    "\n",
    "        x = self.fc6(x)\n",
    "\n",
    "        return self.sigm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "f62a3e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = Net()\n",
    "models.to(device)\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(models.parameters(), lr=5e-6)\n",
    "\n",
    "epochs = 50\n",
    "nn_valid_loss = np.inf\n",
    "nn_f1_score = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "2479bc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \t Training Loss: 0.6911667572028601 \t Validation Loss: 0.6881577730178833 \t F1: 0.0\n",
      "Epoch 11 \t Training Loss: 0.3956431328360714 \t Validation Loss: 0.42071667114893596 \t F1: 0.7522106885910034\n",
      "Epoch 21 \t Training Loss: 0.3143804655479851 \t Validation Loss: 0.4074239093396399 \t F1: 0.7726165658897823\n",
      "Epoch 31 \t Training Loss: 0.2559597501114233 \t Validation Loss: 0.42416863573922053 \t F1: 0.7792592022154067\n",
      "Epoch 41 \t Training Loss: 0.2006947077921967 \t Validation Loss: 0.4799296822812822 \t F1: 0.7691150373882718\n",
      "\n",
      "Качество метрики F1 для Net = 0.773\n",
      "CPU times: total: 6min 58s\n",
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# используем кэш\n",
    "if not os.path.exists(DIR + '/nw_model.pickle'):\n",
    "    # фиксируем state\n",
    "    np.random.seed(RANDOM_STATE)\n",
    "    random.seed(RANDOM_STATE)\n",
    "    torch.manual_seed(RANDOM_STATE)\n",
    "    torch.cuda.manual_seed(RANDOM_STATE)\n",
    "\n",
    "    for e in range(epochs):\n",
    "        train_loss = 0.0\n",
    "        f1_loss = 0.0\n",
    "\n",
    "        models.train()     # Optional when not using Model Specific layer\n",
    "        for data, labels in train_dataloader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            target = models(data)\n",
    "\n",
    "            loss = criterion(target, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        valid_loss = 0.0\n",
    "        models.eval()     # Optional when not using Model Specific layer\n",
    "\n",
    "        for data, labels in test_dataloader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            target = models(data)\n",
    "            loss = criterion(target, labels)\n",
    "            f1_loss += f1_score(labels, target)\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "        if e % 10 == 0:\n",
    "            score = valid_loss / len(test_dataloader)\n",
    "            f1 = f1_loss / len(test_dataloader)\n",
    "\n",
    "            print(f'Epoch {e+1} \\t Training Loss: {train_loss / len(train_dataloader)} \\t Validation Loss: {score} \\t F1: {f1}')\n",
    "\n",
    "            if nn_valid_loss > score:\n",
    "                nn_valid_loss = score\n",
    "                nn_f1_score = f1\n",
    "                torch.save(models.state_dict(), DIR + '/nw_model.pickle')\n",
    "\n",
    "score_info('Net', nn_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0145325",
   "metadata": {},
   "source": [
    "## Тестирование модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "9a794395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Модель</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.747396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.734997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.769766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Net</td>\n",
       "      <td>0.772617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Модель        F1\n",
       "0      LogisticRegression  0.747396\n",
       "1  RandomForestClassifier  0.734997\n",
       "2      CatBoostClassifier  0.769766\n",
       "3                     Net  0.772617"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mdf = pd.DataFrame(data=scores, columns=['Модель', 'F1'])\n",
    "print('Результаты')\n",
    "display(mdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "3d1f722b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=993, out_features=993, bias=True)\n",
       "  (fc2): Linear(in_features=993, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc4): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc5): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc6): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (dp): Dropout(p=0.2, inplace=False)\n",
       "  (relu): LeakyReLU(negative_slope=0.01)\n",
       "  (sigm): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загрузим модель\n",
    "models = Net()\n",
    "models.to(device)\n",
    "\n",
    "models.load_state_dict(torch.load(DIR + '/nw_model.pickle'))\n",
    "models.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "993f7799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3263 entries, 0 to 10875\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   keyword   3237 non-null   object\n",
      " 1   location  2158 non-null   object\n",
      " 2   text      3263 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 102.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(DIR + '/test.csv')\n",
    "df_test.set_index('id', inplace=True)\n",
    "\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "77955c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выполним обработку данных\n",
    "\n",
    "# заполним пропуски\n",
    "df_test['location'] = df_test['location'].fillna('unknown')\n",
    "\n",
    "# новый целевой признак, содержится ли в подстроке location упоминание о стране\n",
    "df_test['isCountry'] = df_test['location'].apply(is_country)\n",
    "\n",
    "# новый целевой признак, содержится ли в подстроке location упоминание о городе\n",
    "df_test['isCity'] = df_test['location'].apply(is_city)\n",
    "\n",
    "# обработаем остальные значения\n",
    "df_test['isUnknown'] = df_test['location'] == 'unknown'\n",
    "df_test['isUnknown'] = df_test['isUnknown'].map({ True: 1, False: 0 })\n",
    "\n",
    "df_test['isOther'] = (df_test['isCity'] == False) & (df_test['isCountry'] == False) & (df_test['isUnknown'] == False)\n",
    "df_test['isOther'] = df_test['isOther'].map({ True: 1, False: 0 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "68f9c7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['keyword'] = df_test['keyword'].fillna('unknown')\n",
    "\n",
    "# создадим вектор признаков\n",
    "df_test = pd.get_dummies(df_test, columns=['keyword'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "7675f587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3263/3263 [02:00<00:00, 27.14it/s]\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=df_test.shape[0]) as pbar:\n",
    "    df_test['text_vector'] = df_test['text'].apply(lambda x: text2vector(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "59926799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание вектора\n",
    "df_test['feature_vector'] = df_test.drop(columns=['text_vector', \n",
    "                                        'text', \n",
    "                                        'location']) \\\n",
    "                            .apply(lambda x: x.values, axis=1)\n",
    "\n",
    "df_test['finish_vector'] = df_test.apply(join_vectors, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "7b6e2ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# вектор\n",
    "features = df_test['finish_vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "77f6ff53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "993"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "996f6fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_scaler = scaler.transform(features.tolist())\n",
    "features_train = torch.FloatTensor(features_scaler.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "84eed0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred = models(features_train.to(device)).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "7fe596eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_binary = torch.round(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "91473a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['target'] = pred_binary\n",
    "df_test['target'] = df_test['target'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "53e651ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['target'].to_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caae545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
